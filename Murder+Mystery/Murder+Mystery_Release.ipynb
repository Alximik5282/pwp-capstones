{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "murder_note = \"\"\"You may call me heartless, a killer, a monster, a murderer, but I'm still NOTHING compared to the villian that Jay was. This whole contest was a sham, an elaborate plot to shame the contestants and feed Jay's massive, massive ego. SURE you think you know him! You've seen him smiling for the cameras, laughing, joking, telling stories, waving his money around like a prop but off camera he was a sinister beast, a cruel cruel taskmaster, he treated all of us like slaves, like cattle, like animals! Do you remember Lindsay, she was the first to go, he called her such horrible things that she cried all night, keeping up all up, crying, crying, and more crying, he broke her with his words. I miss my former cast members, all of them very much. And we had to live with him, live in his home, live in his power, deal with his crazy demands. AND FOR WHAT! DID YOU KNOW THAT THE PRIZE ISN'T REAL? He never intended to marry one of us! The carrot on the stick was gone, all that was left was stick, he told us last night that we were all a terrible terrible disappointment and none of us would ever amount to anything, and that regardless of who won the contest he would never speak to any of us again! It's definitely the things like this you can feel in your gut how wrong he is! Well I showed him, he got what he deserved all right, I showed him, I showed him the person I am! I wasn't going to be pushed around any longer, and I wasn't going to let him go on pretending that he was some saint when all he was was a sick sick twisted man who deserved every bit of what he got. The fans need to know, Jay Stacksby is a vile amalgamation of all things evil and bad and the world is a better place without him.\"\"\"\n",
    "\n",
    "lily_trebuchet_intro = \"\"\"Hi, I'm Lily Trebuchet from East Egg, Long Island. I love cats, hiking, and curling up under a warm blanket with a book. So they gave this little questionnaire to use for our bios so lets get started. What are some of my least favorite household chores? Dishes, oh yes it's definitely the dishes, I just hate doing them, don't you? Who is your favorite actor and why? Hmm, that's a hard one, but I think recently I'll have to go with Michael B. Jordan, every bit of that man is handsome, HANDSOME! Do you remember seeing him shirtless? I can't believe what he does for the cameras! Okay okay next question, what is your perfect date? Well it starts with a nice dinner at a delicious but small restaurant, you know like one of those places where the owner is in the back and comes out to talk to you and ask you how your meal was. My favorite form of art? Another hard one, but I think I'll have to go with music, music you can feel in your whole body and it is electrifying and best of all, you can dance to it! Okay final question, let's see, What are three things you cannot live without? Well first off, my beautiful, beautiful cat Jerry, he is my heart and spirit animal. Second is pasta, definitely pasta, and the third I think is my family, I love all of them very much and they support me in everything I do. I know Jay Stacksby is a handsome man and all of us want to be the first to walk down the aisle with him, but I think he might truly be the one for me. Okay that's it for the bio, I hope you have fun watching the show!\"\"\"\n",
    "\n",
    "myrtle_beech_intro = \"\"\"Salutations. My name? Myrtle. Myrtle Beech. I am a woman of simple tastes. I enjoy reading, thinking, and doing my taxes. I entered this competition because I want a serious relationship. I want a commitment. The last man I dated was too whimsical. He wanted to go on dates that had no plan. No end goal. Sometimes we would just end up wandering the streets after dinner. He called it a \"walk\". A \"walk\" with no destination. Can you imagine? I like every action I take to have a measurable effect. When I see a movie, I like to walk away with insights that I did not have before. When I take a bike ride, there better be a worthy destination at the end of the bike path. Jay seems frivolous at times. This worries me. However, it is my staunch belief that one does not make and keep money without having a modicum of discipline. As such, I am hopeful. I will now list three things I cannot live without. Water. Emery boards. Dogs. Thank you for the opportunity to introduce myself. I look forward to the competition.\"\"\"\n",
    "\n",
    "gregg_t_fishy_intro = \"\"\"A most good day to you all, I am Gregg T Fishy, of the Fishy Enterprise fortune. I am 37 years young, an adventurous spirit and I've never lost my sense of childlike wonder. I do love to be in the backyard gardening and I have the most extraordinary time when I'm fishing. Fishing for what, you might find yourself asking? Why, I happen to always be fishing for compliments of course! I have a stunning pair of radiant blue eyes that will pierce the soul of anyone who dare gaze upon my countenance. I quite enjoy going on long jaunts through garden paths and short walks through greenhouses. I hope that Jay will be as absolutely interesting as he appears on the television, I find that he has some of the most curious tastes in style and humor. When I'm out and about I quite enjoy hearing tales that instill in my heart of hearts the fascination that beguiles my every day life, every fiber of my being scintillates and vascillates with extreme pleasure during one of these charming anecdotes and significantly pleases my beautiful personage. I cannot wait to enjoy being on the television program A Jay To Remember, it certainly seems like a grand time to explore life and love.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_sentence_length(text):\n",
    "    sentence_lengths = []\n",
    "    total = 0\n",
    "    average = 0\n",
    "    \n",
    "    n_1 = text.replace(\"?\", \".\")\n",
    "    n_2 = n_1.replace(\"!\", \".\")\n",
    "    sentences_in_text = n_2.split(\".\")\n",
    "    \n",
    "    for word in sentences_in_text:\n",
    "        sentence_lengths.append(len(word))\n",
    "        return sentence_lengths\n",
    "\n",
    "    for length in sentence_lengths:\n",
    "        total += length\n",
    "        return total\n",
    "    \n",
    "    average = total / len(sentence_lengths)\n",
    "    return average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_text(text):\n",
    "    text.lower()\n",
    "    text.strip()\n",
    "    text.strip(\",\")\n",
    "    text.strip(\"!\")\n",
    "    text.strip(\"?\")\n",
    "    final = text.split(\" \")\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_frequency_table(corpus):\n",
    "    frequency_table = {}\n",
    "    \n",
    "    for element in corpus:\n",
    "        if element not in frequency_table.keys():\n",
    "            frequency_table[element] = 0\n",
    "        if element in frequency_table:\n",
    "            frequency_table[element] += 1\n",
    "    return frequency_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngram_creator(text_list):\n",
    "    new_list = []\n",
    "    \n",
    "    for i in range(0, len(text_list) - 1):\n",
    "        new_list.append(text_list[i] + \" \" + text_list[i + 1])\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextSample:\n",
    "    def __init__(self, text, author):\n",
    "        self.raw_text = text\n",
    "        self.average_sentence_length = get_average_sentence_length(self.raw_text)\n",
    "        self.author = author\n",
    "        self.prepared_text = prepare_text(self.raw_text)\n",
    "        self.word_count_frequency = build_frequency_table(self.prepared_text)\n",
    "        self.ngram_frequency = build_frequency_table(ngram_creator(self.prepared_text))\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return \"\"\"\n",
    "        The author's name: {n}\n",
    "        The average sentence length: {a}\n",
    "        \"\"\".format(n = self.author, a = self.average_sentence_length)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "murderer_sample = TextSample(murder_note, \"murder\")\n",
    "\n",
    "lily_sample = TextSample(lily_trebuchet_intro, \"Lily Trebuchet\")\n",
    "\n",
    "myrtle_sample = TextSample(myrtle_beech_intro, \"Myrle Beech\")\n",
    "\n",
    "gregg_sample = TextSample(gregg_t_fishy_intro, \"Gregg T Fishy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_comparison(table1, table2):\n",
    "    appearances = 0\n",
    "    mutual_appearances = 0\n",
    "    total = 0\n",
    "    \n",
    "    for key1 in table1.keys():\n",
    "        for key2 in table2.keys():\n",
    "            if key1 in key2:\n",
    "                if table1[key1] > table2[key2]:\n",
    "                    mutual_appearances += table2[key2]\n",
    "                    appearances += table1[key1]\n",
    "                elif table1[key1] < table2[key2]:\n",
    "                    mutual_appearances += table1[key1]\n",
    "                    appearances += table2[key2]\n",
    "                elif key1 not in key2:\n",
    "                    appearnces += table1[key1]\n",
    "                    appearnces += table2[key2]\n",
    "                \n",
    "    if appearances == 0:\n",
    "        appearances += 1\n",
    "    total = mutual_appearances / appearances\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percent_difference(value1, value2):\n",
    "    per_dif = abs(value1 - value2) / ((value1 + value2) / 2)\n",
    "    return per_dif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_text_similarity(text_sample1, text_sample2):\n",
    "    total = 0\n",
    "    sentence_length_difference = 0\n",
    "\n",
    "    for num1 in text_sample1.average_sentence_length:\n",
    "        for num2 in text_sample2.average_sentence_length:\n",
    "            sentence_length_difference = percent_difference(num1, num2)\n",
    "    \n",
    "    sentence_length_similarity = abs(1 - sentence_length_difference)\n",
    "    \n",
    "    word_count_similarity = frequency_comparison(text_sample1.word_count_frequency, text_sample2.word_count_frequency)\n",
    "    \n",
    "    ngram_similarity = frequency_comparison(text_sample1.ngram_frequency, text_sample2.ngram_frequency)\n",
    "    \n",
    "    total = (sentence_length_similarity + word_count_similarity + ngram_similarity) / 3\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        The author's name: murder\n",
      "        The average sentence length: [118]\n",
      "        \n",
      "\n",
      "        The author's name: Lily Trebuchet\n",
      "        The average sentence length: [49]\n",
      "        \n",
      "Lily Trebuchet similarity:  0.27790397787246196\n",
      "\n",
      "        The author's name: Myrle Beech\n",
      "        The average sentence length: [11]\n",
      "        \n",
      "Myrle Beech similarity: 0.2835706916274706\n",
      "\n",
      "        The author's name: Gregg T Fishy\n",
      "        The average sentence length: [79]\n",
      "        \n",
      "Gregg T Fishy similarity:  0.4375238506678187\n"
     ]
    }
   ],
   "source": [
    "print(murderer_sample)\n",
    "\n",
    "print(lily_sample)\n",
    "lily_similarity = find_text_similarity(murderer_sample, lily_sample)\n",
    "print(lily_sample.author + \" similarity: \", lily_similarity)\n",
    "\n",
    "print(myrtle_sample)\n",
    "myrtle_similarity = find_text_similarity(murderer_sample, myrtle_sample)\n",
    "print(myrtle_sample.author + \" similarity:\", myrtle_similarity)\n",
    "\n",
    "print(gregg_sample)\n",
    "gregg_similarity = find_text_similarity(murderer_sample, gregg_sample)\n",
    "print(gregg_sample.author + \" similarity: \", gregg_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gregg T Fishy is Dunnit!\n"
     ]
    }
   ],
   "source": [
    "print(gregg_sample.author + \" is Dunnit!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
